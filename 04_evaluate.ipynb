{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import glob\n",
    "import pickle\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Retrieval Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateAll(sampleLens, dbSizes, dbSamplings, hyp_dir, savefile = None):\n",
    "    mrrInfo = np.zeros((len(sampleLens), len(dbSizes), dbSamplings))\n",
    "    for i, sampleLen in enumerate(sampleLens):\n",
    "        print('Evaluating sample len = {}'.format(sampleLen))\n",
    "        for j, dbSize in enumerate(dbSizes):\n",
    "            print('  dbSize = {}'.format(dbSize))\n",
    "            for k in range(dbSamplings):\n",
    "                mrrInfo[i,j,k] = evaluateSingle(sampleLen, dbSize, hyp_dir, k)\n",
    "        \n",
    "    if savefile:\n",
    "        with open(savefile, 'wb') as f:\n",
    "            pickle.dump({'mrrInfo': mrrInfo, 'sampleLens': sampleLens, 'dbSizes': dbSizes, 'dbSamplings': dbSamplings}, f)\n",
    "\n",
    "    return mrrInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateSingle(sampleLen, dbSize, hyp_dir, random_seed = 0):\n",
    "    np.random.seed(random_seed)\n",
    "    numQueries = len(glob.glob('{}/sample{}/*.hyp'.format(hyp_dir, sampleLen)))\n",
    "    gtRanks = []\n",
    "    for pieceNum in range(1, numQueries+1):\n",
    "        if pieceNum % 10 == 1 or pieceNum % 10 == 5: # skip training queries\n",
    "            continue \n",
    "        hyp_file = '{}/sample{}/p{}.hyp'.format(hyp_dir, sampleLen, pieceNum)\n",
    "        d = loadPickle(hyp_file)\n",
    "        fullDBSize = d['dbSize']\n",
    "        rankings = d['sorted_both']\n",
    "        dbPieces = getDBSampling(fullDBSize, pieceNum, dbSize)\n",
    "        for i in range(rankings.shape[0]):\n",
    "            gtRanks.append(determineGroundTruthRank(rankings[i,:], dbPieces, pieceNum))\n",
    "    mrr = np.mean(1/np.array(gtRanks))\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateMultithreaded(sampleLen, dbSize, hyp_dir, dbSamplings, savefile):\n",
    "    print('Processing sampleLen {}, dbSize {}'.format(sampleLen, dbSize))\n",
    "    result = []\n",
    "    for k in range(dbSamplings):\n",
    "        mrr = evaluateSingle(sampleLen, dbSize, hyp_dir, k)\n",
    "        result.append(mrr)\n",
    "    result = np.array(result)\n",
    "    \n",
    "    with open(savefile, 'wb') as f:\n",
    "        pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPickle(pkl_file):\n",
    "    with open(pkl_file, 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDBSampling(fullSize, refId, sampleSize):\n",
    "    withoutRef = np.delete(np.arange(1, fullSize+1), refId-1)\n",
    "    sampling = np.random.choice(withoutRef, size=sampleSize-1, replace=False)\n",
    "    sampling = np.append(sampling, refId)\n",
    "    return sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineGroundTruthRank(predRanking, dbPieces, refId):\n",
    "    rank = 0\n",
    "    for pieceNum in predRanking:\n",
    "        if pieceNum in dbPieces:\n",
    "            rank += 1\n",
    "        if pieceNum == refId:\n",
    "            break\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use single CPU\n",
    "# sampleLens = [10, 20, 50, 100, 200, 500, 1000, 100000]\n",
    "# dbSizes = [1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000]\n",
    "# numDBSamplings = 10\n",
    "# hyp_dir = 'hyps'\n",
    "# savefile = 'mrr.pkl'\n",
    "# evaluateAll(sampleLens, dbSizes, numDBSamplings, hyp_dir, savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use multiple CPUs\n",
    "sampleLens = [10, 20, 50, 100, 200, 500, 1000, 100000]\n",
    "dbSizes = [1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000]\n",
    "numDBSamplings = 10\n",
    "hyp_dir = 'hyps'\n",
    "eval_dir = 'results'\n",
    "savefile = 'mrr.pkl'\n",
    "\n",
    "# prep output directory\n",
    "if not os.path.isdir(eval_dir):\n",
    "    os.makedirs(eval_dir)\n",
    "\n",
    "# number of cores to use\n",
    "n_cores = 25 #multiprocessing.cpu_count()\n",
    "\n",
    "# prep inputs for parallelization\n",
    "inputs = []\n",
    "for i, sampleLen in enumerate(sampleLens):\n",
    "    for j, dbSize in enumerate(dbSizes):\n",
    "        outfile = '{}/sampleLen{}_dbSize{}.pkl'.format(eval_dir, sampleLen, dbSize)\n",
    "        inputs.append((sampleLen, dbSize, hyp_dir, numDBSamplings, outfile))\n",
    "            \n",
    "# process queries in parallel\n",
    "pool = multiprocessing.Pool(processes=n_cores)\n",
    "outputs = list(pool.starmap(evaluateMultithreaded, inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregateResults(eval_dir, sampleLens, dbSizes, numDBSamplings, savefile):\n",
    "    mrr = np.zeros((len(sampleLens), len(dbSizes), numDBSamplings))\n",
    "    for i, sampleLen in enumerate(sampleLens):\n",
    "        for j, dbSize in enumerate(dbSizes):\n",
    "            pkl_file = '{}/sampleLen{}_dbSize{}.pkl'.format(eval_dir, sampleLen, dbSize)\n",
    "            with open(pkl_file, 'rb') as f:\n",
    "                d = pickle.load(f)\n",
    "            mrr[i,j,:] = d\n",
    "    \n",
    "    if savefile:\n",
    "        with open(savefile, 'wb') as f:\n",
    "            pickle.dump({'mrrInfo': mrr, 'sampleLens': sampleLens, 'dbSizes': dbSizes, 'dbSamplings': numDBSamplings}, f)            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregateResults(eval_dir, sampleLens, dbSizes, numDBSamplings, savefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = loadPickle(savefile)\n",
    "sampleLens = d['sampleLens']\n",
    "dbSizes = d['dbSizes']\n",
    "mrr = d['mrrInfo']\n",
    "means = np.mean(mrr, axis=2)\n",
    "stdevs = np.std(mrr, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.arange(len(dbSizes))  # the x locations for the groups\n",
    "width = 0.1  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "for i, sampleLen in enumerate(sampleLens):\n",
    "    if i == len(sampleLens) - 1:\n",
    "        labelStr = 'Full MIDI File'\n",
    "    else:\n",
    "        labelStr = '{}'.format(sampleLen)\n",
    "    ax.bar(ind + width*(i-3.5), means[i,:], width, label=labelStr)\n",
    "    #ax.bar(ind + width*(i-3.5), means[i,:], width, yerr=stdevs[i,:], label='SampleLen = {}'.format(sampleLen))\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('MRR')\n",
    "ax.set_xticks(ind)\n",
    "ax.set_xticklabels([str(dbSize) for dbSize in dbSizes])\n",
    "ax.set_xlabel('Database Size')\n",
    "ax.set_ylim(top=1)\n",
    "ax.legend(title = 'Query Length', loc = 'upper center', framealpha = 1.0, ncol=len(sampleLens), bbox_to_anchor=(0.5, 1.15))\n",
    "ax.yaxis.grid(True, linestyle='--')\n",
    "#fig.tight_layout()\n",
    "#plt.savefig('accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRuntimeInfo(sampleLens, hyp_dir, savefile = None):\n",
    "    '''\n",
    "    Compute average search time per query.\n",
    "    '''\n",
    "    t_avgs = []\n",
    "    for i, sampleLen in enumerate(sampleLens):\n",
    "        hypdir = '{}/sample{}'.format(hyp_dir, sampleLen)\n",
    "        totalDur = 0\n",
    "        fileCount = 0\n",
    "        for hypfile in glob.glob('{}/*.hyp'.format(hypdir)):\n",
    "            d = loadPickle(hypfile)\n",
    "            totalDur += d['profileDur']\n",
    "            fileCount += 1\n",
    "        t_avgs.append(totalDur / fileCount)\n",
    "        \n",
    "    if savefile:\n",
    "        with open(savefile, 'wb') as f:\n",
    "            pickle.dump({'t_avgs': t_avgs}, f)\n",
    "\n",
    "    return t_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_avgs = getRuntimeInfo(sampleLens, hyp_dir, 'runtime.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_avgs # average search times on full 5k database by sample query length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMidiFeatureRuntime(midi_feat_dir):\n",
    "    totalDur = 0\n",
    "    numFiles = 0\n",
    "    for pkl_file in glob.glob('{}/*.pkl'.format(midi_feat_dir)):\n",
    "        with open(pkl_file, 'rb') as f:\n",
    "            d = loadPickle(pkl_file)\n",
    "        totalDur += d['dur']\n",
    "        numFiles += 1\n",
    "    avgTime = totalDur / numFiles\n",
    "    print('Average time to compute MIDI bootleg score: {:.2f} sec'.format(avgTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcMidiFeatureRuntime('midi_feat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SheetMidiRetrieval",
   "language": "python",
   "name": "sheetmidiretrieval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
